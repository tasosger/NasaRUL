{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load - Save Processed Data\n",
        "\n",
        "This notebook handles saving the transformed data to files or databases for downstream use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load transformed data (run transform.ipynb first)\n",
        "# Or load from saved intermediate files if available\n",
        "try:\n",
        "    train = pd.read_csv('train_transformed.csv')\n",
        "    valid = pd.read_csv('valid_transformed.csv')\n",
        "    y_valid = pd.read_csv('y_valid_transformed.csv')\n",
        "    print(\"Loaded transformed data from files\")\n",
        "except:\n",
        "    print(\"Please run transform.ipynb first to create transformed data\")\n",
        "    print(\"Or ensure transformed data files exist in the current directory\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save processed data to CSV files\n",
        "output_dir = 'processed_data'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Save training data\n",
        "train.to_csv(os.path.join(output_dir, 'train_processed.csv'), index=False)\n",
        "print(f\"Saved training data: {train.shape}\")\n",
        "\n",
        "# Save validation data\n",
        "valid.to_csv(os.path.join(output_dir, 'valid_processed.csv'), index=False)\n",
        "print(f\"Saved validation data: {valid.shape}\")\n",
        "\n",
        "# Save RUL validation labels\n",
        "y_valid.to_csv(os.path.join(output_dir, 'y_valid_processed.csv'), index=False)\n",
        "print(f\"Saved RUL validation labels: {y_valid.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify saved files\n",
        "import glob\n",
        "saved_files = glob.glob(os.path.join(output_dir, '*.csv'))\n",
        "print(\"\\nSaved files:\")\n",
        "for file in saved_files:\n",
        "    size = os.path.getsize(file) / (1024 * 1024)  # Size in MB\n",
        "    print(f\"  {os.path.basename(file)}: {size:.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Save to Parquet format for better performance\n",
        "train.to_parquet(os.path.join(output_dir, 'train_processed.parquet'), index=False)\n",
        "valid.to_parquet(os.path.join(output_dir, 'valid_processed.parquet'), index=False)\n",
        "y_valid.to_parquet(os.path.join(output_dir, 'y_valid_processed.parquet'), index=False)\n",
        "print(\"\\nData also saved in Parquet format for efficient storage and loading\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"LOAD COMPLETE\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Training data: {train.shape[0]} rows, {train.shape[1]} columns\")\n",
        "print(f\"Validation data: {valid.shape[0]} rows, {valid.shape[1]} columns\")\n",
        "print(f\"RUL labels: {y_valid.shape[0]} rows\")\n",
        "print(f\"\\nAll processed data saved to '{output_dir}' directory\")\n",
        "print(\"=\"*50)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
