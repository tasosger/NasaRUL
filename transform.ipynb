{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transform - Data Transformation and Feature Engineering\n",
        "\n",
        "This notebook handles data transformations, feature engineering, and data quality checks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "np.random.seed(34)\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load extracted data (run extract.ipynb first)\n",
        "# Or load from saved intermediate files if available\n",
        "try:\n",
        "    train = pd.read_csv('train_extracted.csv')\n",
        "    valid = pd.read_csv('valid_extracted.csv')\n",
        "    y_valid = pd.read_csv('y_valid_extracted.csv')\n",
        "    print(\"Loaded from intermediate files\")\n",
        "except:\n",
        "    # If intermediate files don't exist, run extract cells here\n",
        "    index_names = ['unit_number', 'time_cycles']\n",
        "    setting_names = ['setting_1', 'setting_2', 'setting_3']\n",
        "    sensor_names = ['s_{}'.format(i+1) for i in range(0,21)]\n",
        "    col_names = index_names + setting_names + sensor_names\n",
        "\n",
        "    train = pd.read_csv('train_FD001.txt',sep='\\s+',header=None,index_col=False,names=col_names)\n",
        "    valid = pd.read_csv('test_FD001.txt',sep='\\s+',header=None,index_col=False,names=col_names)\n",
        "    y_valid = pd.read_csv('RUL_FD001.txt',sep='\\s+',header=None,index_col=False,names=['RUL'])\n",
        "    print(\"Loaded directly from source files\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data quality checks\n",
        "print('Shape of the train dataset : ',train.shape)\n",
        "print('Shape of the validation dataset : ',valid.shape)\n",
        "print('Percentage of the validation dataset : ',len(valid)/(len(valid)+len(train)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print('Total None values in the train dataset : ',train.isna().sum().sum())\n",
        "print('Total None values in the validation dataset : ',valid.isna().sum().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exploratory Data Analysis - Basic statistics\n",
        "index_names = ['unit_number', 'time_cycles']\n",
        "train.loc[:,['unit_number','time_cycles']].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize engine lifetimes\n",
        "max_time_cycles=train[index_names].groupby('unit_number').max()\n",
        "plt.figure(figsize=(20,50))\n",
        "ax=max_time_cycles['time_cycles'].plot(kind='barh',width=0.8, stacked=True,align='center')\n",
        "plt.title('Turbofan Engines LifeTime',fontweight='bold',size=30)\n",
        "plt.xlabel('Time cycle',fontweight='bold',size=20)\n",
        "plt.xticks(size=15)\n",
        "plt.ylabel('unit',fontweight='bold',size=20)\n",
        "plt.yticks(size=15)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution of max time cycles\n",
        "sns.displot(max_time_cycles['time_cycles'],kde=True,bins=20,height=6,aspect=2)\n",
        "plt.xlabel('max time cycle')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Engineering: Add RUL (Remaining Useful Life) column\n",
        "def add_RUL_column(df):\n",
        "    train_grouped_by_unit = df.groupby(by='unit_number')\n",
        "    max_time_cycles = train_grouped_by_unit['time_cycles'].max()\n",
        "    merged = df.merge(max_time_cycles.to_frame(name='max_time_cycle'), left_on='unit_number',right_index=True)\n",
        "    merged[\"RUL\"] = merged[\"max_time_cycle\"] - merged['time_cycles']\n",
        "    merged = merged.drop(\"max_time_cycle\", axis=1)\n",
        "    return merged\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply RUL transformation to training data\n",
        "train = add_RUL_column(train)\n",
        "print(\"RUL column added to training data\")\n",
        "train[['unit_number','RUL']].head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify RUL transformation\n",
        "maxrul_u = train.groupby('unit_number').max().reset_index()\n",
        "maxrul_u.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation analysis\n",
        "corr = train.corr()\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "f, ax = plt.subplots(figsize=(10, 10))\n",
        "cmap = sns.diverging_palette(230, 10, as_cmap=True)\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display transformed data summary\n",
        "print(\"Transformed training data shape:\", train.shape)\n",
        "print(\"Transformed validation data shape:\", valid.shape)\n",
        "print(\"\\nTransformed data is ready for loading!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save transformed data for next stage (Load)\n",
        "import os\n",
        "train.to_csv('train_transformed.csv', index=False)\n",
        "valid.to_csv('valid_transformed.csv', index=False)\n",
        "y_valid.to_csv('y_valid_transformed.csv', index=False)\n",
        "print(\"Transformed data saved for loading stage\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
